<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DenysG的个人博客</title>
    <link>https://48474.net/</link>
    <description>Recent content on DenysG的个人博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 Jul 2021 09:38:48 +0800</lastBuildDate><atom:link href="https://48474.net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Docker：清理Docker占用的磁盘空间</title>
      <link>https://48474.net/post/docker-prune/</link>
      <pubDate>Fri, 02 Jul 2021 09:38:48 +0800</pubDate>
      
      <guid>https://48474.net/post/docker-prune/</guid>
      <description>现整理出一些常用的 清理Docker占用的磁盘空间 指令，方便查找。
官方CLI网址 - Docker CLI
 Docker 好， Docker化 好！ 好！ 好！
 容器清理  docker container prune : 仅删除停止运行的容器。 docker rm -f $(docker ps -aq) : 删除所有容器（包括停止的、正在运行的）。 docker container rm -f $(docker container ls -aq): 同上。  镜像清理 docker rmi &amp;lt;image id&amp;gt; ：通过镜像的id来删除指定镜像。
有一些镜像是隐形的：
 子镜像，就是被其他镜像引用的中间镜像，不能被删除。 悬挂状态的镜像，就是不会再被使用的镜像，可以被删除。  其他命令：
 docker image ls -f dangling=true: 可以列出所有悬挂状态的镜像.
并使用命令 docker image rm $(docker image ls -f dangling=true -q) 或 docker image prune 进行删除。 docker image rm $(docker image ls -q) ：删除所有镜像。但正在被容器使用的镜像无法删除。  数据卷清理  docker volume rm $(docker volume ls -q) ：删除不再使用的数据卷。 docker volume prune ：同上。  缓存清理 Docker 18.</description>
    </item>
    
    <item>
      <title>什么是SOCKET ？ Socket - TCP 篇</title>
      <link>https://48474.net/post/waht_it_socket/</link>
      <pubDate>Tue, 03 Nov 2020 03:12:35 +0800</pubDate>
      
      <guid>https://48474.net/post/waht_it_socket/</guid>
      <description>近期工作内容经常会提到 Socket, 但是绝大多数人对于这个还是一个很蒙圈的状态，所以从网上找了一堆的资料，简单的将 Socket 做一个详细一些的解释。
Socket 直译是 插座 的意思，一般翻译成 套接字，简单的来说就是网络上的两个程序通过一个双向的通信连接实现数据的交换，这个连接的一端称为一个socket。
在百科中的解释是 Socket本质是编程接口(API)，对TCP/IP的封装 ，所以要想搞明白 Socket 就要先弄明白什么是 TCP/IP ，但是要想搞明白 TCP/IP 又要先弄明 网络七层协议，这个路绕的有点大，下面就一个一个搞清楚。
网络七层协议 放式系统互联通信参考模型（英语：Open System Interconnection Reference Model，缩写为 OSI），简称为OSI模型（OSI model），就是通常所说的网络七层协议。
第1层 物理层(Physical Layer) 在局部局域网上传送帧，它负责管理电脑通信设备和网络媒体之间的互通。包括了针脚、电压、线缆规范、集线器、中继器、网卡、主机适配器等。在这一层，数据的单位称为比特（bit）。属于物理层定义的典型规范代表包括：EIA/TIA RS-232、EIA/TIA RS-449、V.35、RJ-45等。如 RJ-45，就是日常电脑连接的网线的水晶头的规格。
第2层 数据链接层(Data Link Layer) 负责网络寻址、错误侦测和改错。将物理层提供的可能出错的物理连接改造成逻辑上无差错的数据链路，并对物理层的原始数据进行数据封装。数据链路层中的数据封装是指：封装的数据信息中，包含了地址段和数据段等。地址段含有点对点发送节点和接收节点的地址（如MAC），控制段用来表示数格连接帧的类型，数据段包含实际要传输的数据。例如以太网、无线局域网（Wi-Fi）等。
第3层 网络层(Network Layer) 决定数据的路径选择和转寄，将网络表头（NH）加至数据包，以形成分组。网络表头包含了网络数据。例如:互联网协议（IP）等。
第4层 传输层(Transport Layer) 把传输表头（TH）加至数据以形成数据包。传输表头包含了所使用的协议等发送信息。例如:传输控制协议义（TCP、UDP）等。
第5层 会话层(Session Layer) 负责在数据传输中设置和维护电脑网络中两台电脑之间的通信连接。
第6层 表达层(Presentation Layer) 把数据转换为能与接收者的系统格式兼容并适合传输的格式。
第7层 应用层(Application Layer) 提供为应用软件而设的界面，以设置与另一应用软件之间的通信。例如: HTTP，HTTPS，FTP，TELNET，SSH，SMTP，POP3等。应用层直接和应用程序接口并提供常见的网络应用服务，应用层也向第六层表示层发出请求。
 上述主要内容来自 维基百科
 TCP/IP TCP/IP协议族（英语：TCP/IP Protocol Suite，或TCP/IP Protocols），简称TCP/IP，名称源自该协议家族的两个核心协议：TCP（Transmission Control Protocol 传输控制协议）和IP（Internet Protocol 互联网协议）。</description>
    </item>
    
    <item>
      <title>折腾日志(1) -- 自用树莓派内网穿透搭建GITEA</title>
      <link>https://48474.net/post/toss-log-01-raspberrypi/</link>
      <pubDate>Wed, 14 Oct 2020 12:25:15 +0800</pubDate>
      
      <guid>https://48474.net/post/toss-log-01-raspberrypi/</guid>
      <description>自备树莓派4B  这台自行组装的树莓派4B，主要用途: 存储，应用服务。
   安装树莓派系统, 并且安装到树莓派到硬盘中
这里不多说安装树莓派的方法，可以自行搜索 度娘 或 谷歌
  我的树莓派是啥样子的？？ (最近搭建了个图床可以上图了) 无图无真相。 主板 1 块： 树莓派4B 8G
  SSD硬盘 2块：
一块 256G(上面红色的),
另一块 512G(下面银色的)。 全部是 浦科特（Plextor） M8VC。
扩展板 2块：
  X829 扩展板:: 一款2.5&#39; 双硬盘 NAS扩展板 树莓派4B&amp;ndash;树莓派NAS集群 X829 扩展板
  X735扩展板:: 电源管理和温控风扇扩展板 树莓派4B&amp;ndash;X735电源管理和温控风扇扩展板
  俯视图 右侧接口 左侧HHD指示灯 安装好docker，frpc 这2个服务应用   以上都安装好了，就可以部署自己的服务器啦。
 开始折腾部署 Gitea  因为树莓派是ARM架构的, 所以原来保存的docker镜像都要重新下载
   Pull docker images</description>
    </item>
    
    <item>
      <title>使用 ss 命令代替 netstat</title>
      <link>https://48474.net/post/ss-replace-netstat/</link>
      <pubDate>Wed, 03 Jun 2020 04:25:15 +0800</pubDate>
      
      <guid>https://48474.net/post/ss-replace-netstat/</guid>
      <description>ss 是Socket Statistics的缩写。
顾名思义，ss 命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。
和netstat说再见的原因 当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat /proc/net/tcp，执行速度都会很慢。可能你不会有切身的感受，但请相信我，当服务器维持的连接达到上万个的时候，使用netstat等于浪费 生命，而用ss才是节省时间。
天下武功唯快不破。ss快的秘诀在于，它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux 内核中第一手的信息，这就确保了ss的快捷高效。当然，如果你的系统中没有tcp_diag，ss也可以正常运行，只是效率会变得稍慢。（但仍然比 netstat要快。）
用数据说话 为了让你更坚决的和netstat说再见，列举一些测试数据，以便证明ss的确名不虚传。
当服务器维持3万个socket连接，Admin需要计算具体的连接数量时，不同情况的耗时如下：
netstat -at | wc 耗时 15.60 秒 ss -atr | wc 耗时 5.40 秒（未利用tcp_diag） ss -atr | wc 耗时 0.47 秒（利用tcp_diag） 好马配上好鞍 几乎所有的Linux系统都会默认包含netstat命令，但并非所有系统都会默认包含ss命令。netstat 命令是 net-tools 工具集中的一员：
# apt-cache show net-tools Package: net-tools Version: 1.60+git20180626.aebd88e-1 而ss命令是iproute2工具集中的一员：
# apt-cache show iproute2 Package: iproute2 Version: 4.20.0-2 如果你无法使用ss命令，那么可能是缺少了 iproute2 ，需要安装一下：
# apt install -y iproute2 从某种意义上说，iproute2 工具集几乎可以替代掉 net-tools 工具集，具体的替代方案是这样的：</description>
    </item>
    
    <item>
      <title>自尊，自强，自信，自律，自省，自觉</title>
      <link>https://48474.net/post/days-0418/</link>
      <pubDate>Sat, 18 Apr 2020 00:42:15 +0800</pubDate>
      
      <guid>https://48474.net/post/days-0418/</guid>
      <description>** 自尊，自强，自信，自律，自省，自觉 **
自尊 自尊是人格健全者的标志之一。自尊心是性格中一种高尚的品质，自尊的人关心自我形象，积极向上，有追求目标。自尊促使人积极向上。
但自尊过了头往往是自卑的表现。自卑的人通常有两种表现，或是自轻自贱，妄自菲薄，或是狂妄自大，容不得别人的半点意见，实际上这是缺乏自信的表现。
自强 自强就是上进心，上进心就是不断寻求新领域、追求新成就的一种难以抑制的一种主动、积极、阳光、向上渴望成功、渴望被他人及社会所承认的一种冲动。这种来自于内心的冲动是前进的源泉，缺乏这种冲动所做的事情往往是被逼出来的，逼上梁山，与主动上梁山其结果是不同的。因为如果一个人总是安于现状，不思进取，那就毫无疑问不会取得新的进展与成就。
自信 自信是对自己未来的一种乐观积极的态度，是对自己的智力、能力以及潜在智慧、能力的一种肯定。自信是对自己、对他人的悦纳，是一种意念，一种意志。
自信并不意味着没有失败，没有风险，而是具有面对失败的勇气、战胜失败的信念和把握成功机会的能力。性格中有了自信，生活里就会充满快乐。自信心建立在客观的基础之上，是成功人士必不可少的性格特征之一。很难想象一个没有自信心的人会有所作为。自信是在肯定自己存在价值的基础上，了解自己的长处和短处，在工作学习中扬长避短，并相信自己的能力和努力。
自律 自律就是自我控制与自我调节，这是一个人良好性格的重要标志。
坚韧不拔的毅力来自于此； 刻苦勤奋来自于此； 承受失败挫折忍耐力来自于此； 乐观豁达的心胸、助人为乐善意来自于此； 坚持不懈永不言败也来自于此。
一个人如果不善于自控，则意味着不能有效地发动、支配自己或抑制自己激情、控制自己的冲动，对未来的成长过程有害无益。很多人由于不能控制自己的激情和冲动行为或失去理智、或犯罪堕落甚至危及生命。自我控制主要靠后天自身的修养。
自省 自省首先是明确自己的人生目标，对该做的和不该做的有清晰的认识，使自己的行为服务于目标。其次，要养成“说一不二”的习惯。当然这并不是指固执、刻板，而是指自控能力的培养需要有坚定的意志。要经常反省自己努力从思想上认识从行动上克服懒惰、消极、逃避、贪婪等缺点。
自觉 人的成功等动力来自于自我。擂鼓珠、算盘珠、佛顶珠，佛顶珠根本不动，算盘珠拨了才动，擂鼓珠闻声而动。牛不饮水强按头是被动的，只有坚持主动精神，自己控制自己，自己把握自己，自己激励自己，才有可能在激烈的竞争中崭露头角。
只有如此才会实现自我爬坡，自我攀登。
PS：
放下一切，让心归零！
人生最难是放下，放下一切，才能让心归零！放下一切，是为了成全自己，让自己摆脱痛苦的纠缠，烦恼的骚扰，让自己得到解脱，让内心重获自由。
我们活着，只要心是自由的，人生便是快活的，可如果心被过往所禁锢住，那这一生便会与痛苦相伴，所以，我们都要学会放下，最好能够放下一切，让心归零，你才能整整地解救自己。
万般皆苦，唯有自救，而自救最好的方式，也许就是放下一切，让心归零吧！
往后余生，希望我们都能够想开点，看淡点，别太执着，该放的放，该忘的忘，让自己好过点！
愿你积极乐观，开心过好每一天！</description>
    </item>
    
    <item>
      <title>《诗经·邶风·击鼓》</title>
      <link>https://48474.net/post/days/</link>
      <pubDate>Sun, 15 Mar 2020 01:42:15 +0800</pubDate>
      
      <guid>https://48474.net/post/days/</guid>
      <description>《诗经·邶风·击鼓》
击鼓其镗，踊跃用兵。土国城漕，我独南行。 从孙子仲，平陈与宋。不我以归，忧心有忡。 爰居爰处？爰丧其马？于以求之？于林之下。 死生契阔，与子成说。执子之手，与子偕老。 于嗟阔兮，不我活兮。于嗟洵兮，不我信兮。</description>
    </item>
    
    <item>
      <title>Mysql 的 sql_mode 配置</title>
      <link>https://48474.net/post/mysql-sql_mode/</link>
      <pubDate>Mon, 05 Nov 2018 02:31:05 +0800</pubDate>
      
      <guid>https://48474.net/post/mysql-sql_mode/</guid>
      <description>在 oracle 或 sqlserver 或 PostgreSQL 中，如果某个表的字段设置成 not null， insert 或 update 时不给这个字段赋值，必然报错。
比如下面这样：
表 t_test(id,name)中 id, name 都不允许为空，
insert into t_test(name) values(&#39;xxx&#39;) 必然报错，这是天经地义的事情，但是在mysql中这是有可能成功，具体取决于 sql_mode 的设置。
sql_mode 可以分为二大类：
  所谓的宽松无敌模式
my.cnf 中 sql_mode 设置为空或仅 NO_ENGINE_SUBSTITUTION.
这种模式下，not null 的字段，在 insert 或 update 时不设置值也能成功，db在插入时，会自动给默认值。
比如: int 会给 0 值，甚至可以把 abc 赋值给 int型 的字段（当然，db会自动忽略该值，变成默认值 0 ）
  所谓的严格模式
具体有很多可选值，设置成严格模式后，mysql 就跟传统的 oracle、sqlserver、 PostgreSQL, 表现一致了，这也是我个人强烈推荐的模式。
  最后，无耻的从网上抄一段贴在这里备份：
如果使用 mysql，为了继续保留大家使用 oracle 的习惯，可以对 mysql 的sql_mode 设置如下：</description>
    </item>
    
    <item>
      <title>Docker 常用命令（一）</title>
      <link>https://48474.net/post/docker-readme01/</link>
      <pubDate>Mon, 05 Nov 2018 00:08:48 +0800</pubDate>
      
      <guid>https://48474.net/post/docker-readme01/</guid>
      <description>使用了一段时间 docker 了。现整理出一些常用的 docker cli 指令，方便查找。
官方CLI网址 - Docker CLI
 对开发，测试和运维人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。 确保了应用运行环境一致性，从而不会再出现 “这段代码在我机器上没问题啊？！” 这类问题。 由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。   Docker 好， Docker化 好！ 好！ 好！
 开发常用的指令 # docker search debian  # docker pull debian:&amp;lt;tag&amp;gt; // 启动一个容器，并且在运行结束后删除容器 # docker run -it --rm debian // 启动一个容器并命名为mydebian # docker run --name mydebian -it --rm debian //启动容器并执行多个命令 # docker run -it --rm debian sh -c &amp;#34;cmd1 &amp;amp;&amp;amp; cmd2&amp;#34; // 启动容器并挂载本机目录 # docker run -it --rm \ --mount type=bind,source=/&amp;lt;host-path&amp;gt;, \  target=/&amp;lt;container-path&amp;gt; \  debian //上面的简化 # docker run -it --rm -v &amp;lt;host-path&amp;gt;:&amp;lt;container-path&amp;gt; debian 创建新的网络,并在启动本地容器的时候 指定ip # docker network create --subnet=172.</description>
    </item>
    
    <item>
      <title>Dockerfile 参考文档 （一）</title>
      <link>https://48474.net/post/dockerfile-reference-1/</link>
      <pubDate>Sun, 02 Sep 2018 12:01:39 +0800</pubDate>
      
      <guid>https://48474.net/post/dockerfile-reference-1/</guid>
      <description>Dockerfile Dockerfile 是由一系列命令和参数构成的脚本，一个 Dockerfile 里面包含了构建整个 image 的完整命令。Docker通过 docker build 执行Dockerfile 中的一系列命令自动构建 image。
Dockerfile 其语法非常简单，此页面描述了您可以在 Dockerfile 中使用的命令。 阅读此页面后，你可以参阅Dockerfile最佳实践。
Usage docker build 命令从 Dockerfile 和 context 构建image。context 是 PATH 或URL 处的文件。PATH 本地文件目录。 URL 是Git repository的位置。
context 以递归方式处理。因此，PATH 包括任何子目录，URL 包括repository及submodules。一个使用当前目录作为 context 的简单构建命令：
$ docker build . Sending build context to Docker daemon 6.51 MB ... 构建由Docker守护程序运行，而不是由CLI运行。构建过程所做的第一件事是将整个context（递归地）发送给守护进程。大多数情况下，最好是将 Dockerfile 和所需文件复制到一个空的目录，再到这个目录进行构建。
 警告：不要使用根目录 / 作为PATH，因为它会导致构建将硬盘驱动器的所有内容传输到Docker守护程序。
 build时添加文件，通过 Dockerfile 引用指令中指定的文件，例如 COPY 指令。要增加构建的性能，请通过将.dockerignore 文件添加到 context 目录中来排除文件和目录。有关如何创建 .dockerignore 文件的信息，请参阅此页上的文档。</description>
    </item>
    
    <item>
      <title>gRPC：Google开源的基于HTTP/2和ProtoBuf的通用RPC框架</title>
      <link>https://48474.net/post/grpc-google-http2-protobuf/</link>
      <pubDate>Wed, 15 Aug 2018 11:16:15 +0800</pubDate>
      
      <guid>https://48474.net/post/grpc-google-http2-protobuf/</guid>
      <description>gRPC是一个高性能、通用的开源RPC框架，其由Google主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers)序列化协议开发，且支持众多开发语言。gRPC提供了一种简单的方法来精确地定义服务和为iOS、Android和后台支持服务自动生成可靠性很强的客户端功能库。客户端充分利用高级流和链接功能，从而有助于节省带宽、降低的TCP链接次数、节省CPU使用、和电池寿命。
gRPC具有以下重要特征：
  强大的IDL特性
gRPC使用ProtoBuf来定义服务，ProtoBuf是由Google开发的一种数据序列化协议（类似于XML、JSON、hessian）。ProtoBuf能够将数据进行序列化，并广泛应用在数据存储、通信协议等方面。不过，当前gRPC仅支持 Protobuf ，且不支持在浏览器中使用。由于gRPC的设计能够支持支持多种数据格式，所以读者能够很容易实现对其他数据格式（如XML、JSON等）的支持。
定义服务的示例代码如下：
message HelloRequest { string greeting = 1; } message HelloResponse { string reply = 1; } service HelloService { rpc SayHello(HelloRequest) returns (HelloResponse); }   支持多语言
gRPC支持多种语言，并能够基于语言自动生成客户端和服务端功能库。目前，在GitHub上已提供了 C版本grpc、Java版本grpc-java 和 Go版本grpc-go，其它语言的版本正在积极开发中，其中 grpc支持 C、C++、Node.js、Python、Ruby、Objective-C、PHP 和 C# 等语言，grpc-java 已经支持Android开发。
  基于HTTP/2标准设计
由于gRPC基于HTTP/2标准设计，所以相对于其他RPC框架，gRPC带来了更多强大功能，如双向流、头部压缩、多复用请求等。这些功能给移动设备带来重大益处，如节省带宽、降低TCP链接次数、节省CPU使用和延长电池寿命等。同时，gRPC还能够提高了云端服务和Web应用的性能。gRPC既能够在客户端应用，也能够在服务器端应用，从而以透明的方式实现客户端和服务器端的通信和简化通信系统的构建。
  gRPC已经应用在Google的云服务和对外提供的API中，其主要应用场景如下：
 低延迟、高扩展性、分布式的系统 同云服务器进行通信的移动应用客户端 设计语言独立、高效、精确的新协议 便于各方面扩展的分层设计，如认证、负载均衡、日志记录、监控等  近日，gRPC开发团队宣布gRPC基于 BSD 3-Clause License 许可协议开源，相关代码已托管在GitHub上。当前已有Google和移动支付公司Square以及其他组织或个人为该项目贡献代码。有兴趣的读者可以在GitHub选择需要的语言版本，并根据提供的README文档尝试gRPC的功能，或者参考FAQ，以获得对gRPC更多信息。此外，在gRPC-common仓库中，还提供了例子、快速入门指南等相关文档。</description>
    </item>
    
    <item>
      <title>VPS Debian8 删除一些没用的服务的方法</title>
      <link>https://48474.net/post/vps_debian_unremove_service/</link>
      <pubDate>Mon, 16 Jan 2017 13:18:39 +0800</pubDate>
      
      <guid>https://48474.net/post/vps_debian_unremove_service/</guid>
      <description>本人喜欢使用linux的debian发行版本。也用过其他的发行版本。
现在使用的vps是ufovps出售的香港云服务器。
安装的是linux的Debian8版本。
安装好后远程登陆vps后查看有如下几个服务已经安装并在运行。
   exim4 rpcbind nfs+portmap  以上这些服务我都不使用，需要关闭。方法如下：
删除 exim4 服务 exim4服务 开放 port :25 大家都知道这个端口做啥都吧！
$ apt-get purge --auto-remove exim4 exim4-base exim4-config exim4-daemon-light $ rm -rf /var/log/exim4/ 删除 rpcbind 服务 rpcbind 服务 此服务开启port :111 这个端口。
$ apt-get purge --auto-remove rpcbind 删除nfs服务 $ apt-get purge --auto-remove nfs-kernel-server nfs-common portmap 如果不删除只是关闭相关服务，可以如下执行
$ systemctl disable nfs-common $ systemctl disable rpcbind $ systemctl disable exim4 $ systemctl stop nfs-common $ systemctl stop rpcbind $ systemctl stop exim4  PS：几句废话。</description>
    </item>
    
    <item>
      <title>Error: /usr/local must be writable! 解决方法</title>
      <link>https://48474.net/post/brew_update_error_fix/</link>
      <pubDate>Mon, 26 Dec 2016 12:51:15 +0800</pubDate>
      
      <guid>https://48474.net/post/brew_update_error_fix/</guid>
      <description>今天在Mac下执行brew update时出现以下错误提示：
 $ brew update
Error: /usr/local must be writable!
 以前一直默认用的好好的,突然出现这种情况导致不能正常使用了。 按我习惯性的方法，修改下目录的权限吧
 $ sudo chmod -R g+w /usr/local
$ brew update
还是出现错误提示 Error: /usr/local must be writable!
 有点晕啦，怎么还是有问题呢？ 仔细想了下，自检以下吧。
 $ brew doctor
 上面是修改目录的写权限，现在修改目录的用户权限吧！！
 $ sudo chown -R $(whoami) /usr/local
 再次执行brew doctor, 正常啦！！！
再次执行brew update, 终于正常，正常啦！！！
总结一下：
 升级了macos后没执行brew doctor，导致brew 出现问题。 升级系统，一定要检测下第三方软件是否能正常工作。 检测工作没执行到底呀。  </description>
    </item>
    
    <item>
      <title>CaddyServer使用记录</title>
      <link>https://48474.net/post/caddy-guide/</link>
      <pubDate>Thu, 22 Dec 2016 14:37:00 +0800</pubDate>
      
      <guid>https://48474.net/post/caddy-guide/</guid>
      <description>Caddy是一个Golang编写的服务器软件，官方的宣传语“The HTTP/2 web server with automatic HTTPS”以及“Serve The Web Like It&amp;rsquo;s 2016”简明表达了这个软件的优点和趋势，它拥有Apache或者Nginx所具有的web server模块，同时还有一些很有特色的功能，比如:
 HTTP/2 Automatic HTTPS Multi-core Websockets Markdown IPv6 Git FastCGI &amp;hellip;  在去年就开始使用Caddy，它提供的便捷配置，部署了内部测试服务的Web服务器、个人网站的Web服务器。配置项的语法简单粗暴，非常简洁明了。比nginx简单多了。
下面举几个例子：
 简单的测试网站  :8530 { root /var/www/test_site }  使用git同步测试环境  :8530 { root /var/www/test_site/public git git.int5262.com/user_name/project_name { path ../ interval 60 } fastcgi / 127.0.0.1:9001 php }  站点跳转  http://48474.com, http://www.48474.com { redir https://48474.com{uri} } 看看吧，是不是太简单了？ 配置起来能具体到简洁到哭的指令。 详细文档请看官方的User Guide。
启动caddy也很简单
/path/to/caddy -conf=&amp;quot;/path/to/caddy/caddyfile&amp;quot;  Caddy官网 https://caddyserver.</description>
    </item>
    
    <item>
      <title>管理git生成的多个ssh key</title>
      <link>https://48474.net/post/git_more_ssh_keygen/</link>
      <pubDate>Thu, 31 Dec 2015 09:24:10 +0800</pubDate>
      
      <guid>https://48474.net/post/git_more_ssh_keygen/</guid>
      <description>问题阐述 当有多个git账号的时候，比如一个github，用于自己进行一些开发活动，再来一个gitlab，一般是公司内部的git。这两者你的邮箱如果不同的话，就会涉及到一个问题，生成第二个git的key的时候会覆盖第一个的key，导致必然有一个用不了。
问题解决 我们可以在~/.ssh目录下新建一个config文件配置一下，就可以解决问题
具体步骤   生成第一个ssh key(这里我用于github，用的gmail邮箱)
ssh-keygen -t rsa -b 4096 -C &amp;quot;your_email@example.com&amp;quot; 这里不要一路回车，让你选择在哪里选择存放key的时候写个名字，比如 id_rsa_github，之后的两个可以回车。
完成之后我们可以看到~/.ssh目录下多了两个文件。
id_rsa_github id_rsa_github.pub   生成第二个ssh key（这里我用于gitlab，用的是公司邮箱）
ssh-keygen -t rsa -b 4096 -C &amp;quot;your_email@example.com&amp;quot; 还是一样不要一路回车，在第一个对话的时候继续写个名字，比如 id_rsa_gitlab,之后的两个可以回车。
完成之后我们可以看到~/.ssh目录下多了两个文件。（一个公钥一个私钥）
id_rsa_gitlab id_rsa_gitlab.pub   打开ssh-agent
这里如果你用的github官方的bash，ssh-agent -s,
如果是其他的，比如msysgit,eval $(ssh-agent -s)。
  添加私钥
ssh-add ~/.ssh/id_rsa_github ssh-add ~/.ssh/id_rsa_gitlab   创建并修改config文件
  windows
新建一个txt文本，然后将名字后缀一起改成config即可。
  linux|unix
在bash下的话直接touch config 即可。
# gitlab Host git.int-5262.com //别名 HostName git.</description>
    </item>
    
    <item>
      <title>使用Service Interface的优缺点</title>
      <link>https://48474.net/post/service_interface_advantages_and_disadvantages/</link>
      <pubDate>Sat, 10 Oct 2015 18:18:56 +0800</pubDate>
      
      <guid>https://48474.net/post/service_interface_advantages_and_disadvantages/</guid>
      <description>使用 Service Interface 模式会导致下面的优缺点： 优点  服务接口机制与应用逻辑分隔。这种分隔使您能够轻松地添加新的接口以及更改基础应用程序的实现，同时对使用者的影响最小。 通过将服务接口代码与服务实现代码分隔开来，您就能够在不同层上部署这两部分代码，这样有可能提高解决方案的部署灵活性。  缺点  很多平台使公开应用程序功能变得很简单。但是，这可能会导致作出粒度方面的错误决定。如果接口粒度太细，可能会导致最后必须很多次调用服务，才能执行特定操作。您需要对服务接口进行相应设计，使其适合网络通信或过程外通信。 服务所提供的每个新增服务接口都会增加在更改服务所公开的功能时所需的工作量。 Service Interface 模式增加了复杂性和性能开销，这对于很简单的面向服务的应用程序来说可能不是很合适  </description>
    </item>
    
    <item>
      <title>Golang程序配置方案小结</title>
      <link>https://48474.net/post/config-solutions-for-golang-app/</link>
      <pubDate>Sat, 10 Oct 2015 13:44:31 +0800</pubDate>
      
      <guid>https://48474.net/post/config-solutions-for-golang-app/</guid>
      <description>在Twitter上看到一篇关于Golang程序配置方案总结的系列文章（一个mini series，共6篇），原文链接：在这里。我觉得不错，这里粗略整理（非全文翻译）一下，供大家参考。
一、背景 无论使用任何编程语言开发应用，都离不开配置数据。配置数据提供的形式有多样，不外乎命令行选项(options)、参数（parameters)，环境变量（envvars)以及配置文件等。Golang也不例外。Golang内置flag标准库，可以用来支持部分命令行选项和参数的解析；Golang通过os包提 供的方法可以获取当前环境变量；但Golang没有规定标准配置文件格式(虽说内置支持xml、json)，多通过第三方 包来解决配置文件读取的问题。Golang配置相关的第三方包很多，作者在本文中给出的配置方案中就包含了主流的第三方配置数据操作包。
文章作者认为一个良好的应用配置层次应该是这样的：
 程序内内置配置项的初始默认值 配置文件中的配置项值可以覆盖(override)程序内配置项的默认值。 命令行选项和参数值具有最高优先级，可以override前两层的配置项值。  下面就按作者的思路循序渐进探讨golang程序配置方案。
二、解析命令行选项和参数 这一节关注golang程序如何访问命令行选项和参数。
golang对访问到命令行参数提供了内建的支持：
//cmdlineargs.go package main import ( // &amp;quot;fmt&amp;quot; &amp;quot;os&amp;quot; &amp;quot;path/filepath&amp;quot; ) func main() { println(&amp;quot;I am &amp;quot;, os.Args[0]) baseName := filepath.Base(os.Args[0]) println(&amp;quot;The base name is &amp;quot;, baseName) // The length of array a can be discovered using the built-in function len println(&amp;quot;Argument # is &amp;quot;, len(os.Args)) // the first command line arguments if len(os.Args) &amp;gt; 1 { println(&amp;quot;The first command line argument: &amp;quot;, os.</description>
    </item>
    
    <item>
      <title>存储知识：比较在线、近线和离线存储</title>
      <link>https://48474.net/post/storage_knowledge/</link>
      <pubDate>Sat, 10 Oct 2015 12:23:12 +0800</pubDate>
      
      <guid>https://48474.net/post/storage_knowledge/</guid>
      <description>传统存储数据的方式有两种：在线存储和离线存储。
在线存储 在线存储是指存储设备和所存储的数据时刻保持“在线”状态，可供用户随意读取，满足计算平台对数据访问的速度要求。就像PC机中常用的磁盘存储模式一样。一般在线存储设备为磁盘和磁盘阵列等存储设备，价格相对昂贵，但性能较好。
离线存储 离线存储是对在线存储数据的备份，以防范可能发生的数据灾难。离线存储的数据不常被调用，一般也远离系统应用，所以人们用“离线”来生动地描述这种存储方式。
离线存储介质上的数据在读写时是顺序进行的。当需要读取数据时，需要把磁带卷到头，再进行定位。当需要对已写入的数据进行修改时，所有的数据都需要全部进行改写。因此，离线存储的访问速度慢、效率低。离线存储的典型产品是磁带库，价格相对低廉。
近线存储 所谓近线存储(NearStore)，是随着客户存储环境的细化所提出的一个概念，所谓的近线存储，外延相对较广泛，主要定位于客户在线存储和离线存储之间的应用。就是指将那些并不是经常用到，或者说数据的访问量并不大的数据存放在性能较低的存储设备上。但同时对这些的设备要求是寻址迅速、传输率高。(例如客户一些长期保存的不长用的文件的归档)。因此，近线存储对性能要求相对来说并不高，但又要求相对较好的访问性能。同时多数情况下由于不常用的数据要占总数据量的比较大的比重，这也就要求近线存储设备在需要容量相对较大。</description>
    </item>
    
    <item>
      <title>xorm 说明</title>
      <link>https://48474.net/post/xorm-readme/</link>
      <pubDate>Fri, 09 Oct 2015 16:13:10 +0800</pubDate>
      
      <guid>https://48474.net/post/xorm-readme/</guid>
      <description>xorm是一个简单而强大的Go语言ORM库. 通过它可以使数据库操作非常简便。xorm的目标并不是让你完全不去学习SQL，我们认为SQL并不会为ORM所替代，但是ORM将可以解决绝大部分的简单SQL需求。xorm支持两种风格的混用。
特性  支持Struct和数据库表之间的灵活映射，并支持自动同步表结构 事务支持 支持原始SQL语句和ORM操作的混合执行 使用连写来简化调用 支持使用Id, In, Where, Limit, Join, Having, Table, Sql, Cols等函数和结构体等方式作为条件 支持级联加载Struct 支持LRU缓存(支持memory, memcache, leveldb, redis缓存Store) 和 Redis缓存 支持反转，即根据数据库自动生成xorm的结构体 支持事件 支持created, updated, deleted和version记录版本（即乐观锁）  驱动支持 xorm当前支持的驱动和数据库如下：
 Mysql: github.com/go-sql-driver/mysql MyMysql: github.com/ziutek/mymysql/godrv SQLite: github.com/mattn/go-sqlite3 Postgres: github.com/lib/pq MsSql: github.com/denisenkom/go-mssqldb MsSql: github.com/lunny/godbc  安装 推荐使用 gopm 进行安装：
gopm get github.com/go-xorm/xorm  或者您也可以使用go工具进行安装：
go get github.com/go-xorm/xorm  文档  操作指南 GoWalker代码文档 Godoc代码文档  讨论 请加入QQ群：280360085 进行讨论。
贡献 如果您也想为Xorm贡献您的力量，请查看 CONTRIBUTING</description>
    </item>
    
  </channel>
</rss>
